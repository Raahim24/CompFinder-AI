{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "subjects_df = pd.read_csv('data/cleaned/subjects_cleaned.csv')\n",
    "candidates_df = pd.read_csv('data/engineered/candidates_pairs_features.csv')\n",
    "comps_df = pd.read_csv('data/engineered/comps_pairs_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to use\n",
    "feature_cols = [\n",
    "    'gla_diff', 'lot_size_diff', 'bedroom_diff', 'bathroom_diff', 'room_count_diff',\n",
    "    'same_property_type', 'same_storey_type', 'sold_recently_90'\n",
    "]\n",
    "\n",
    "# Label columns for supervised training\n",
    "comps_df['label'] = 1\n",
    "candidates_df['label'] = 0\n",
    "\n",
    "# Concatenate comps and candidates for training\n",
    "train_data = pd.concat([comps_df, candidates_df], ignore_index=True)\n",
    "X = train_data[feature_cols]\n",
    "y = train_data['label']\n",
    "groups = train_data.groupby('orderID').size().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved as xgboost_model.json\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "dtrain.set_group(groups)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0.5,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=200)\n",
    "model.save_model('xgboost_model.json')\n",
    "print(\"✅ Model trained and saved as xgboost_model.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score every candidate (so every subject can get their top 3)\n",
    "dmatrix = xgb.DMatrix(candidates_df[feature_cols])\n",
    "candidates_df['score'] = model.predict(dmatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top3 = []\n",
    "\n",
    "for oid in subjects_df['orderID']:\n",
    "    group = candidates_df[candidates_df['orderID'] == oid].copy()\n",
    "    if not group.empty:\n",
    "        top_n = group.nlargest(3, 'score')\n",
    "        if len(top_n) < 3:\n",
    "            pad = pd.DataFrame([{'orderID': oid}] * (3 - len(top_n)))\n",
    "            top_n = pd.concat([top_n, pad], ignore_index=True)\n",
    "        all_top3.append(top_n)\n",
    "    else:\n",
    "        pad = pd.DataFrame([{'orderID': oid}] * 3)\n",
    "        all_top3.append(pad)\n",
    "\n",
    "top3_full = pd.concat(all_top3, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean, labeled columns! Saved as final_subjects_top3_candidates.csv\n"
     ]
    }
   ],
   "source": [
    "# Use suffixes to clarify which columns are for subject vs candidate\n",
    "\n",
    "# Subject columns\n",
    "subject_cols = [\n",
    "    'orderID', 'address', 'gla_clean', 'bedrooms_clean', 'bathrooms_clean',\n",
    "    'room_count_clean', 'lot_size_clean', 'structure_type', 'stories_clean', 'effective_date_clean'\n",
    "]\n",
    "\n",
    "# Candidate columns\n",
    "candidate_cols = [\n",
    "    'id', 'address', 'gla_clean', 'bedrooms_clean', 'bathrooms_clean',\n",
    "    'room_count_clean', 'lot_size_clean', 'structure_type', 'stories_clean', 'close_date_clean'\n",
    "]\n",
    "\n",
    "# Make copies to avoid in-place changes\n",
    "subjects_info = subjects_df[subject_cols].drop_duplicates(subset=['orderID']).copy()\n",
    "subjects_info = subjects_info.rename(columns={col: 'subject_' + col if col != 'orderID' else col for col in subject_cols})\n",
    "\n",
    "candidates_info = candidates_df[['orderID', 'id'] + candidate_cols[1:]].copy()\n",
    "candidates_info = candidates_info.rename(columns={col: 'candidate_' + col if col not in ['orderID', 'id'] else col for col in candidate_cols})\n",
    "\n",
    "output = top3_full.merge(subjects_info, on='orderID', how='left')\n",
    "output = output.merge(candidates_info, on=['orderID', 'id'], how='left')\n",
    "\n",
    "# Final column list: orderID, id, subject columns, candidate columns, score\n",
    "final_cols = ['orderID', 'id'] + [c for c in subjects_info.columns if c != 'orderID'] + [c for c in candidates_info.columns if c not in ['orderID', 'id']] + ['score']\n",
    "output = output[final_cols]\n",
    "\n",
    "# Rank\n",
    "output['rank'] = output.groupby('orderID')['score'].rank(method='first', ascending=False)\n",
    "\n",
    "output.to_csv('final_subjects_top3_candidates.csv', index=False)\n",
    "print(\"✅ Clean, labeled columns! Saved as final_subjects_top3_candidates.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved as final_subjects_top3_candidates.csv\n"
     ]
    }
   ],
   "source": [
    "output['rank'] = output.groupby('orderID')['score'].rank(method='first', ascending=False)\n",
    "\n",
    "output.to_csv('final_subjects_top3_candidates.csv', index=False)\n",
    "print(\"✅ Saved as final_subjects_top3_candidates.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@3: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Prepare a set of (orderID, id) pairs that are true expert comps\n",
    "comp_pairs = set(zip(candidates_df['orderID'], candidates_df['id']))\n",
    "\n",
    "# Mark for each row in output if it's a true comp\n",
    "output['is_true_comp'] = output.apply(lambda row: (row['orderID'], row['id']) in comp_pairs, axis=1)\n",
    "\n",
    "# For each subject, did any of their top 3 candidates match a comp?\n",
    "precision_at_3 = output.groupby('orderID')['is_true_comp'].max().mean()\n",
    "\n",
    "print(f\"Precision@3: {precision_at_3:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
