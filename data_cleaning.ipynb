{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Appraisal Comp Recommendation System\n",
    "\n",
    "--- \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re  # For pattern matching in text\n",
    "from dateutil import parser  # For parsing various date formats\n",
    "from datetime import datetime\n",
    "from rapidfuzz import process, fuzz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cell 2: Load Cleaned Data\n",
    "\n",
    "We'll start by loading our cleaned subjects, comps, and candidates tables that were saved during data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded!\n",
      "Subjects:   88\n",
      "Comps:      264\n",
      "Candidates: 9820\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data from CSV files\n",
    "subjects_df = pd.read_csv('datasets/data/subjects_raw.csv')\n",
    "comps_df = pd.read_csv('datasets/data/comps_raw.csv')\n",
    "candidates_df = pd.read_csv('datasets/data/candidates_raw.csv')\n",
    "\n",
    "print(\"âœ… Data loaded!\")\n",
    "print(f\"Subjects:   {len(subjects_df)}\")\n",
    "print(f\"Comps:      {len(comps_df)}\")\n",
    "print(f\"Candidates: {len(candidates_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 - 7: Summarize Unique Values for Selected Features\n",
    "\n",
    "This function helps you **quickly explore all unique values** for just the columns you care about, in any DataFrame (subjects, comps, candidates).\n",
    "\n",
    "**How it works:**\n",
    "- Pass your DataFrame and a list of column names you want to inspect.\n",
    "- Returns a summary table showing:\n",
    "  - The feature (column) name\n",
    "  - All unique values found in that column\n",
    "  - The total number of unique values\n",
    "- If a column isnâ€™t found, it displays \"(Column missing in DataFrame)\" for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "**Example usage:**\n",
    "```python\n",
    "subjects_uni_df = summarize_selected_unique_features(subjects_df, subject_cols)\n",
    "comps_uni_df = summarize_selected_unique_features(comps_df, comp_cols)\n",
    "candidates_uni_df = summarize_selected_unique_features(candidates_df, candidate_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_selected_unique_features(df, columns):\n",
    "    \"\"\"\n",
    "    Shows all unique values for selected columns in a DataFrame.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to summarize.\n",
    "        columns (list): List of column names to check.\n",
    "    Returns:\n",
    "        pd.DataFrame: Summary table of unique values per selected feature.\n",
    "    \"\"\"\n",
    "    feature_names = []\n",
    "    unique_vals = []\n",
    "    num_uniques = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            uniques = df[col].unique()\n",
    "            feature_names.append(col)\n",
    "            unique_vals.append(list(uniques))\n",
    "            num_uniques.append(len(uniques))\n",
    "        else:\n",
    "            feature_names.append(col)\n",
    "            unique_vals.append([\"(Column missing in DataFrame)\"])\n",
    "            num_uniques.append(0)\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Feature\": feature_names,\n",
    "        \"Unique_Values\": unique_vals,\n",
    "        \"Num_Unique\": num_uniques\n",
    "    })\n",
    "    \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns you want to see (from your message above)\n",
    "subject_cols = [\n",
    "    \"effective_date\", \"lot_size_sf\", \"structure_type\", \"style\", \"room_total\",\n",
    "    \"num_beds\", \"gla\", \"num_baths\", \"condition\"\n",
    "]\n",
    "\n",
    "comp_cols = [\n",
    "    \"distance_to_subject\", \"prop_type\", \"stories\", \"sale_date\", \"lot_size\",\n",
    "    \"condition\", \"gla\", \"room_count\", \"bed_count\", \"bath_count\"\n",
    "]\n",
    "\n",
    "candidate_cols = [\n",
    "    \"bedrooms\", \"gla\", \"property_sub_type\", \"structure_type\", \"style\",\n",
    "    \"levels\", \"room_count\", \"full_baths\", \"half_baths\", \"lot_size_sf\",\n",
    "    \"close_date\", \"latitude\", \"longitude\"\n",
    "]\n",
    "\n",
    "# Run the function for each DataFrame\n",
    "subjects_uni_df = summarize_selected_unique_features(subjects_df, subject_cols)\n",
    "comps_uni_df = summarize_selected_unique_features(comps_df, comp_cols)\n",
    "candidates_uni_df = summarize_selected_unique_features(candidates_df, candidate_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Dates to YYYY-MM-DD Format\n",
    "\n",
    "This function converts date strings from different formats (like `\"Apr/11/2025\"` or `\"2025-01-13\"`) into a standard format: **YYYY-MM-DD**.\n",
    "\n",
    "**Key points:**\n",
    "- Handles both `\"Apr/11/2025\"` and `\"2025-01-13\"` formats.\n",
    "- Returns `None` for missing or invalid dates.\n",
    "- Prints a warning if a date can't be parsed (helps you debug messy data).\n",
    "\n",
    "---\n",
    "**Example usage:**\n",
    "```python\n",
    "test_dates = ['Apr/11/2025', 'Oct/25/2024', '2025-01-13', None, 'bad_date']\n",
    "for date in test_dates:\n",
    "    print(f\"{date} â†’ {standardize_date(date)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr/11/2025 â†’ 2025-04-11\n",
      "Oct/25/2024 â†’ 2024-10-25\n",
      "2025-01-13 â†’ 2025-01-13\n",
      "None â†’ None\n"
     ]
    }
   ],
   "source": [
    "def clean_date(date_string):\n",
    "    \"\"\"\n",
    "    Cleans date strings and converts them to a standard format.\n",
    "    \n",
    "    Examples:\n",
    "    - 'Apr/11/2025' â†’ '2025-04-11'\n",
    "    - 'Oct/25/2024' â†’ '2024-10-25'\n",
    "    - nan â†’ None\n",
    "    \n",
    "    Parameters:\n",
    "    - date_string: The date value to clean (could be string or NaN)\n",
    "    \n",
    "    Returns:\n",
    "    - Standardized date string or None\n",
    "    \"\"\"\n",
    "    # Check if the value is missing (NaN or None)\n",
    "    if pd.isna(date_string) or date_string is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Use dateutil parser to handle various formats automatically\n",
    "        parsed_date = parser.parse(str(date_string))\n",
    "        # Return in standard YYYY-MM-DD format\n",
    "        return parsed_date.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        # If parsing fails, return None\n",
    "        print(f\"Could not parse date: {date_string}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "test_dates = ['Apr/11/2025', 'Oct/25/2024', '2025-01-13', None]\n",
    "for date in test_dates:\n",
    "    print(f\"{date} â†’ {clean_date(date)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Area/Numeric Strings with Units\n",
    "\n",
    "This function **extracts and standardizes numeric area values** from messy strings with units.  \n",
    "It's designed to handle values like `\"1500 SqFt\"`, `\"78 SqM\"`, `\"1.25 Acres\"`, dimension strings like `\"49' x 119'\"`, and even hybrid formats like `\"50' x 118' / 5,900 sf\"`.\n",
    "\n",
    "**How it works:**\n",
    "- **If both a dimension and an explicit area are present**, it uses the area (e.g., `\"50' x 118' / 5,900 sf\"` returns `5900`).\n",
    "- Handles common area units: **SqFt, SqM, Acres** (all returned in square feet).\n",
    "- Removes commas, plus/minus signs, and ignores N/A values.\n",
    "- For plain numbers (no unit), assumes square feet.\n",
    "- Returns `None` if the value is missing or can't be parsed.\n",
    "\n",
    "**Example usage:**\n",
    "```python\n",
    "test_values = [\n",
    "    \"1500 SqFt\", \"78 SqM\", \"1.25 Acres\", \"n/a\", \"3,555.5\",\n",
    "    \"50' x 118' / 5,900 sf\", \"49' x 119'\", \"60' x 110' / 6,600 sf\", \"82700\", \"58 SqM\"\n",
    "]\n",
    "for val in test_values:\n",
    "    print(f\"{val} â†’ {clean_numeric_with_units(val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 SqFt â†’ 1500.0\n",
      "78 SqM â†’ 839.592\n",
      "1.25 Acres â†’ 54450.0\n",
      "n/a â†’ None\n",
      "3,555.5 â†’ 3555.5\n",
      "50' x 118' / 5,900 sf â†’ 5900.0\n",
      "49' x 119' â†’ 5831.0\n",
      "60' x 110' / 6,600 sf â†’ 6600.0\n",
      "486 SQ M â†’ 5231.304\n",
      "0.5ac â†’ 21780.0\n"
     ]
    }
   ],
   "source": [
    "def clean_numeric_with_units(value):\n",
    "    \"\"\"\n",
    "    Extracts numeric values from strings with units and returns area in sqft.\n",
    "    - If both a dimension and explicit area are given, prefers the area (e.g., '50\\' x 118\\' / 5,900 sf' returns 5900).\n",
    "    - Handles 'SqFt', 'SqM', 'Acre', dimension strings, commas, +/-.\n",
    "    - Returns float in sqft or None.\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "\n",
    "    value_str = str(value).lower().strip()\n",
    "    if value_str in ['n/a', 'na', 'nan', '', 'n/a condominium', 'n/a-condo land']:\n",
    "        return None\n",
    "    value_str = value_str.replace(',', '').replace('+/-', '')\n",
    "\n",
    "    # First, check for explicit numeric area in the string (e.g., '/ 5900 sf')\n",
    "    area_match = re.findall(r'(\\d+\\.?\\d*)\\s*(?:sq ?ft|sf|sq\\.? ?ft|s\\.?f\\.?)', value_str)\n",
    "    if area_match:\n",
    "        # If multiple, get the biggest (more likely to be the correct one)\n",
    "        return float(max([float(x) for x in area_match]))\n",
    "\n",
    "    # If not, check for dimension: e.g., 50' x 118'\n",
    "    dim_match = re.search(r'(\\d+\\.?\\d*)\\s*[\\'ft]?\\s*[xÃ—]\\s*(\\d+\\.?\\d*)\\s*[\\'ft]?', value_str)\n",
    "    if dim_match:\n",
    "        width = float(dim_match.group(1))\n",
    "        length = float(dim_match.group(2))\n",
    "        return width * length\n",
    "\n",
    "    # Check for acres\n",
    "    if 'acre' in value_str or 'ac' in value_str:\n",
    "        acre_match = re.search(r'(\\d+\\.?\\d*)', value_str)\n",
    "        if acre_match:\n",
    "            return float(acre_match.group(1)) * 43560\n",
    "\n",
    "    # Check for sqm\n",
    "    if 'sqm' in value_str or 'sq m' in value_str:\n",
    "        sqm_match = re.search(r'(\\d+\\.?\\d*)', value_str)\n",
    "        if sqm_match:\n",
    "            return float(sqm_match.group(1)) * 10.764\n",
    "\n",
    "    # Check for plain number (assume sqft)\n",
    "    number_match = re.search(r'(\\d+\\.?\\d*)', value_str)\n",
    "    if number_match:\n",
    "        return float(number_match.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "# Test\n",
    "test_values = [\n",
    "    \"1500 SqFt\", \"78 SqM\", \"1.25 Acres\", \"n/a\", \"3,555.5\",\n",
    "    \"50' x 118' / 5,900 sf\", \"49' x 119'\", \"60' x 110' / 6,600 sf\", \"486 SQ M\", \"0.5ac\"\n",
    "]\n",
    "for val in test_values:\n",
    "    print(f\"{val} â†’ {clean_numeric_with_units(val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Standardize Room Count Values\n",
    "\n",
    "This function, `clean_room_count`, cleans up room count strings and converts them to a single float value.\n",
    "\n",
    "**How it works:**\n",
    "- Handles simple numbers (`'6' â†’ 6.0`)\n",
    "- Handles composite counts (`'6+3' â†’ 9.0`)\n",
    "- Ignores missing, empty, or N/A values\n",
    "- Returns `None` if the value can't be converted\n",
    "\n",
    "**Example usage:**\n",
    "```python\n",
    "test_rooms = ['6', '6+3', '12+4', '15', None, 'n/a', '8+2']\n",
    "for room in test_rooms:\n",
    "    print(f\"{room} â†’ {clean_room_count(room)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 â†’ 6.0\n",
      "6+3 â†’ 9.0\n",
      "12+4 â†’ 16.0\n",
      "15 â†’ 15.0\n",
      "None â†’ None\n",
      "n/a â†’ None\n",
      "8+2 â†’ 10.0\n"
     ]
    }
   ],
   "source": [
    "def clean_room_count(value):\n",
    "    \"\"\"\n",
    "    Cleans room count values.\n",
    "\n",
    "    Examples:\n",
    "    - '6' â†’ 6.0\n",
    "    - '6+3' â†’ 9.0 (e.g., main rooms + den/bonus)\n",
    "    - '8+2' â†’ 10.0\n",
    "    - nan, 'n/a', '' â†’ None\n",
    "\n",
    "    Parameters:\n",
    "    - value: The room count value\n",
    "\n",
    "    Returns:\n",
    "    - Float total room count or None\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "\n",
    "    value_str = str(value).strip()\n",
    "\n",
    "    # Check for empty or n/a values\n",
    "    if value_str.lower() in ['n/a', 'na', '', 'nan']:\n",
    "        return None\n",
    "\n",
    "    # Handle \"X+Y\" format (e.g., \"6+3\")\n",
    "    if '+' in value_str:\n",
    "        parts = value_str.split('+')\n",
    "        try:\n",
    "            total = sum(float(part.strip()) for part in parts)\n",
    "            return total\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # Try to convert directly to float\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "test_rooms = ['6', '6+3', '12+4', '15', None, 'n/a', '8+2']\n",
    "for room in test_rooms:\n",
    "    print(f\"{room} â†’ {clean_room_count(room)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Standardize Bathroom Count Values\n",
    "\n",
    "The `clean_bathroom_count` function standardizes various messy bathroom count formats and converts them to a single float value (where half baths count as 0.5).\n",
    "\n",
    "**How it works:**\n",
    "- Supports formats like:\n",
    "  - `'2:0'` or `'2:1'` (full:half bath notation)\n",
    "  - `'2F 1H'` or `'3F'` (X full, Y half notation)\n",
    "  - `'2 Full/1Half'` or similar (case-insensitive)\n",
    "  - Simple numbers like `'3'`\n",
    "- Missing/empty/N/A values return `None`\n",
    "- Returns a **float** with half baths counted as `0.5` (e.g., `2:1` â†’ `2.5`)\n",
    "\n",
    "**Example usage:**\n",
    "```python\n",
    "test_bathrooms = ['2:0', '2:1', '2F 1H', '3F', '1:2', '2 Full/1Half', '3', None]\n",
    "for bath in test_bathrooms:\n",
    "    print(f\"{bath} â†’ {clean_bathroom_count(bath)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:0 â†’ 2.0\n",
      "2:1 â†’ 2.5\n",
      "2F 1H â†’ 2.5\n",
      "3F â†’ 3.0\n",
      "1:2 â†’ 2.0\n",
      "2F1P â†’ 2.5\n",
      "3 â†’ 3.0\n",
      "None â†’ None\n"
     ]
    }
   ],
   "source": [
    "def clean_bathroom_count(value):\n",
    "    \"\"\"\n",
    "    Cleans bathroom count values with various formats.\n",
    "    \n",
    "    Examples:\n",
    "    - '2:0' â†’ 2.0 (2 full, 0 half)\n",
    "    - '2:1' â†’ 2.5 (2 full, 1 half)\n",
    "    - '2F 1H' â†’ 2.5 (2 full, 1 half)\n",
    "    - '3F' â†’ 3.0 (3 full)\n",
    "    - '1:1' â†’ 1.5\n",
    "    \n",
    "    Parameters:\n",
    "    - value: The bathroom count value\n",
    "    \n",
    "    Returns:\n",
    "    - Float number of bathrooms (half baths count as 0.5) or None\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "    \n",
    "    value_str = str(value).upper().strip()\n",
    "\n",
    "    value_str = value_str.replace('P', 'H')\n",
    "    \n",
    "    # Check for empty or n/a values\n",
    "    if value_str.lower() in ['n/a', 'na', '', 'nan']:\n",
    "        return None\n",
    "    \n",
    "    # Handle \"X:Y\" format (full:half)\n",
    "    if ':' in value_str:\n",
    "        parts = value_str.split(':')\n",
    "        try:\n",
    "            full = float(parts[0].strip())\n",
    "            half = float(parts[1].strip()) if len(parts) > 1 else 0\n",
    "            return full + (half * 0.5)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Handle \"XF YH\" format (X full, Y half)\n",
    "    if 'F' in value_str or 'H' in value_str:\n",
    "        full_match = re.search(r'(\\d+)\\s*F', value_str)\n",
    "        half_match = re.search(r'(\\d+)\\s*H', value_str)\n",
    "        \n",
    "        full = float(full_match.group(1)) if full_match else 0\n",
    "        half = float(half_match.group(1)) if half_match else 0\n",
    "        \n",
    "        return full + (half * 0.5)\n",
    "    \n",
    "    # Handle \"X Full/Y Half\" format\n",
    "    if 'FULL' in value_str or 'HALF' in value_str:\n",
    "        full_match = re.search(r'(\\d+)\\s*FULL', value_str)\n",
    "        half_match = re.search(r'(\\d+)\\s*HALF', value_str)\n",
    "        \n",
    "        full = float(full_match.group(1)) if full_match else 0\n",
    "        half = float(half_match.group(1)) if half_match else 0\n",
    "        \n",
    "        return full + (half * 0.5)\n",
    "    \n",
    "    # Try direct conversion\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "test_bathrooms = ['2:0', '2:1', '2F 1H', '3F', '1:2', '2F1P', '3', None]\n",
    "for bath in test_bathrooms:\n",
    "    print(f\"{bath} â†’ {clean_bathroom_count(bath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 KM â†’ 0.15\n",
      "0.21 km â†’ 0.21\n",
      ".05 km â†’ 0.05\n",
      "None â†’ None\n"
     ]
    }
   ],
   "source": [
    "def clean_distance(value):\n",
    "    \"\"\"\n",
    "    Cleans distance values and converts to kilometers.\n",
    "    \n",
    "    Examples:\n",
    "    - '0.15 KM' â†’ 0.15\n",
    "    - '0.21 km' â†’ 0.21\n",
    "    - '.05 km' â†’ 0.05\n",
    "    \n",
    "    Parameters:\n",
    "    - value: The distance value\n",
    "    \n",
    "    Returns:\n",
    "    - Float distance in kilometers or None\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "    \n",
    "    value_str = str(value).lower().strip()\n",
    "    \n",
    "    # Remove 'km' and spaces\n",
    "    value_str = value_str.replace('km', '').strip()\n",
    "    \n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "test_distances = ['0.15 KM', '0.21 km', '.05 km', None]\n",
    "for dist in test_distances:\n",
    "    print(f\"{dist} â†’ {clean_distance(dist)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property Type Mapping\n",
    "\n",
    "This dictionary maps messy or alternate property type names to our standard set of property types (`CANONICAL_TYPES`).  \n",
    "Any value not in this list will be set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_map = {\n",
    "    # Detached houses\n",
    "    \"detached\": \"Detached\",\n",
    "    \"detached single family\": \"Detached\",\n",
    "    \"single family\": \"Detached\",\n",
    "    \"single family residence\": \"Detached\",\n",
    "    \"rural resid\": \"Detached\",\n",
    "    \"rural residential\": \"Detached\",\n",
    "    \"agriculture\": \"Detached\",\n",
    "    \"farm\": \"Detached\",\n",
    "    \"freehold\": \"Detached\",\n",
    "    \"mobile\": \"Detached\",\n",
    "    \"mobile home\": \"Detached\",\n",
    "    \"mobiletrailer\": \"Detached\",\n",
    "    \"mobile trailer\": \"Detached\",\n",
    "\n",
    "    # Semi-detached and Link homes\n",
    "    \"semi-detached\": \"Semi Detached\",\n",
    "    \"semi detached\": \"Semi Detached\",\n",
    "    \"semi detached (half duplex)\": \"Semi Detached\",\n",
    "    \"link\": \"Semi Detached\",\n",
    "\n",
    "    # Townhouses and similar\n",
    "    \"townhouse\": \"Townhouse\",\n",
    "    \"freehold townhouse\": \"Townhouse\",\n",
    "    \"row/townhouse\": \"Townhouse\",\n",
    "    \"row townhouse\": \"Townhouse\",\n",
    "    \"row unit\": \"Townhouse\",\n",
    "    \"row unit 2 storey\": \"Townhouse\",\n",
    "    \"row unit 3 storey\": \"Townhouse\",\n",
    "    \"stacked\": \"Townhouse\",\n",
    "    \"stacked townhouse\": \"Townhouse\",\n",
    "\n",
    "    # Condos\n",
    "    \"condo apt\": \"Condominium\",\n",
    "    \"condo townhouse\": \"Condominium\",\n",
    "    \"condo apartment\": \"Condominium\",\n",
    "    \"condo/apt unit\": \"Condominium\",\n",
    "    \"condo unit\": \"Condominium\",\n",
    "    \"common element condo\": \"Condominium\",\n",
    "    \"apartment\": \"Condominium\",\n",
    "\n",
    "    # Duplexes, Triplexes, Fourplexes\n",
    "    \"duplex\": \"Duplex\",\n",
    "    \"over-under\": \"Duplex\",\n",
    "    \"over under\": \"Duplex\",\n",
    "    \"duplex up/down\": \"Duplex\",\n",
    "    \"full duplex\": \"Duplex\",\n",
    "    \"triplex\": \"Triplex\",\n",
    "    \"fourplex\": \"Fourplex\",\n",
    "    \"4 plex\": \"Fourplex\",\n",
    "}\n",
    "\n",
    "CANONICAL_TYPES = [\n",
    "    \"Townhouse\", \"Detached\", \"Condominium\", \"Semi Detached\",\n",
    "    \"High Rise Apartment\", \"Low Rise Apartment\", \"Duplex\", \"Triplex\", \"Fourplex\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapid Fuzzy Function\n",
    "\n",
    "This function maps a property type string to a standardized value using our manual mapping:\n",
    "\n",
    "- Checks for an **exact match** in the mapping dictionary.\n",
    "- If no exact match, uses **fuzzy string matching** (`rapidfuzz`) to find the closest match above the `score_cutoff` threshold.\n",
    "- Returns the standardized type if found, otherwise returns `None`.\n",
    "\n",
    "\n",
    "#### **Example Usage**\n",
    "Suppose you have some messy property type values in your dataset:\n",
    "\n",
    "```python\n",
    "values = [\"detachd\", \"row unit\", \"condo aprtment\", \"semi det\", \"moblie home\"]\n",
    "\n",
    "detachd         -> Detached\n",
    "row unit        -> Townhouse\n",
    "condo aprtment  -> Condominium\n",
    "semi det        -> Semi Detached\n",
    "moblie home     -> Detached\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_type_fuzzy(value, mapping, score_cutoff=80):\n",
    "    \"\"\"\n",
    "    Returns mapped type if a close match exists in the mapping dict, else None.\n",
    "    Uses rapidfuzz for fuzzy string matching.\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return None\n",
    "    value = str(value).lower().strip()\n",
    "    # Exact match\n",
    "    if value in mapping:\n",
    "        return mapping[value]\n",
    "    # Fuzzy match\n",
    "    best, score, _ = process.extractOne(\n",
    "        value, list(mapping.keys()), scorer=fuzz.ratio\n",
    "    )\n",
    "    if score >= score_cutoff:\n",
    "        return mapping[best]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cononical check function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical_check(mapped_type):\n",
    "    \"\"\"Return mapped_type if in canonical list, else None\"\"\"\n",
    "    if mapped_type in CANONICAL_TYPES:\n",
    "        return mapped_type\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property Type Standardization\n",
    "\n",
    "The `standardize_property_type` function combines `property_sub_type` and `structure_type` from each property record and returns a single, standardized property type.\n",
    "\n",
    "#### How it works:\n",
    "- **Prefers `property_sub_type`** if available, otherwise uses `structure_type`.\n",
    "- **Manual & fuzzy matching:** First tries to map the value to a standard type using our manual dictionary (with fuzzy matching for typos and close matches).\n",
    "- **Canonical check:** Only returns the type if itâ€™s in the approved `CANONICAL_TYPES` list.\n",
    "- **Substring & keyword logic:** For complex or combined values, it looks for canonical type substrings or key terms (e.g., \"condo\", \"duplex\") to determine the best match.\n",
    "- **Returns `None`** if the value cannot be matched to a canonical property type.\n",
    "\n",
    "This ensures all property types are consistently categorized for analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: {'property_sub_type': 'Freehold Townhouse', 'structure_type': None} â†’ Townhouse\n",
      "Test 2: {'property_sub_type': None, 'structure_type': 'Detached, 2-Storey'} â†’ Detached\n",
      "Test 3: {'property_sub_type': None, 'structure_type': None} â†’ None\n",
      "Test 4: {'property_sub_type': 'Duplex', 'structure_type': 'Detached'} â†’ Duplex\n",
      "Test 5: {'property_sub_type': 'Condo Townhouse', 'structure_type': 'Condo Townhouse'} â†’ Condominium\n",
      "Test 6: {'property_sub_type': 'Triplex', 'structure_type': 'Semi-Detached'} â†’ Triplex\n",
      "Test 7: {'property_sub_type': 'Apartment', 'structure_type': ''} â†’ Condominium\n",
      "Test 8: {'property_sub_type': '', 'structure_type': 'MobileHome'} â†’ Detached\n",
      "Test 9: {'property_sub_type': 'Semi Detached', 'structure_type': 'Duplex'} â†’ Semi Detached\n",
      "Test 10: {'property_sub_type': 'Bungalow', 'structure_type': 'Detached, Bungalow'} â†’ None\n"
     ]
    }
   ],
   "source": [
    "def standardize_property_type(row):\n",
    "    \"\"\"\n",
    "    Combines property_sub_type and structure_type intelligently.\n",
    "    Always returns a value from CANONICAL_TYPES or None.\n",
    "    \"\"\"\n",
    "    sub_type = row.get('property_sub_type', None)\n",
    "    struct_type = row.get('structure_type', None)\n",
    "    sub_type = str(sub_type).strip().lower() if pd.notna(sub_type) and sub_type not in [None, ''] else None\n",
    "    struct_type = str(struct_type).strip().lower() if pd.notna(struct_type) and struct_type not in [None, ''] else None\n",
    "\n",
    "    # Prefer sub_type if both exist\n",
    "    value = sub_type if sub_type else struct_type\n",
    "    if not value:\n",
    "        return None\n",
    "\n",
    "    # Try manual_type_map (exact + fuzzy)\n",
    "    mapped_type = get_manual_type_fuzzy(value, manual_map, score_cutoff=80)\n",
    "    result = canonical_check(mapped_type)\n",
    "    if result is not None:\n",
    "        return result\n",
    "\n",
    "    # Try canonical type substrings\n",
    "    for canon in CANONICAL_TYPES:\n",
    "        if canon.lower() in value:\n",
    "            return canon\n",
    "\n",
    "    # Keyword-based logic (catch broad classes)\n",
    "    if \"condo\" in value:\n",
    "        return \"Condominium\"\n",
    "    if \"townhouse\" in value or \"row unit\" in value:\n",
    "        return \"Townhouse\"\n",
    "    if \"duplex\" in value:\n",
    "        return \"Duplex\"\n",
    "    if \"triplex\" in value:\n",
    "        return \"Triplex\"\n",
    "    if \"fourplex\" in value or \"4 plex\" in value:\n",
    "        return \"Fourplex\"\n",
    "    if \"semi\" in value:\n",
    "        return \"Semi Detached\"\n",
    "    if \"detached\" in value or \"single family\" in value or \"mobile\" in value or \"farm\" in value:\n",
    "        return \"Detached\"\n",
    "\n",
    "    # Fallback: None (doesn't match canonical)\n",
    "    return None\n",
    "\n",
    "# ---- TEST CASES ----\n",
    "test_rows = [\n",
    "    {'property_sub_type': 'Freehold Townhouse', 'structure_type': None},\n",
    "    {'property_sub_type': None, 'structure_type': 'Detached, 2-Storey'},\n",
    "    {'property_sub_type': None, 'structure_type': None},\n",
    "    {'property_sub_type': 'Duplex', 'structure_type': 'Detached'},\n",
    "    {'property_sub_type': 'Condo Townhouse', 'structure_type': 'Condo Townhouse'},\n",
    "    {'property_sub_type': 'Triplex', 'structure_type': 'Semi-Detached'},\n",
    "    {'property_sub_type': 'Apartment', 'structure_type': ''},\n",
    "    {'property_sub_type': '', 'structure_type': 'MobileHome'},\n",
    "    {'property_sub_type': 'Semi Detached', 'structure_type': 'Duplex'},\n",
    "    {'property_sub_type': 'Bungalow', 'structure_type': 'Detached, Bungalow'},\n",
    " \n",
    "]\n",
    "\n",
    "for i, row in enumerate(test_rows, 1):\n",
    "    print(f\"Test {i}: {row} â†’ {standardize_property_type(row)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story/Style Mapping\n",
    "\n",
    "`STORY_GROUPS` lists our standard house style types.\n",
    "\n",
    "`STOREY_MAP` converts messy or alternate style values into those standard groups.\n",
    "\n",
    "Values not found in the map become `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORY_GROUPS = [\n",
    "    \"Bungalow\",\n",
    "    \"Bungalow Raised\",\n",
    "    \"1 Storey\",\n",
    "    \"1.5 Storey\",\n",
    "    \"2 Storey\",\n",
    "    \"2.5 Storey\",\n",
    "    \"3 Storey\",\n",
    "    \"3+ Storey\",\n",
    "    \"Split Level\",\n",
    "    \"Bi-Level\"\n",
    "]\n",
    "\n",
    "STOREY_MAP = {\n",
    "    # Bungalow types\n",
    "    \"bungalow\": \"Bungalow\",\n",
    "    \"bungalow raised\": \"Bungalow Raised\",\n",
    "    \"bungalow(1 storey)\": \"Bungalow\",\n",
    "    \"bungaloft\": \"Bungalow\",   # Optionally, you could keep this separate\n",
    "    \"bun\": \"Bungalow\",         # Typo, treat as bungalow\n",
    "\n",
    "    # Single storey\n",
    "    \"1 storey\": \"1 Storey\",\n",
    "    \"1 level\": \"1 Storey\",\n",
    "    \"1\": \"1 Storey\",\n",
    "    \"one\": \"1 Storey\",\n",
    "    \"single level apartment\": \"1 Storey\",\n",
    "    \"1 Storey/Apt\": \"1 Storey\",\n",
    "    \"one level\": \"1 Storey\",\n",
    "\n",
    "    # 1.5 Storey\n",
    "    \"1.5 storey\": \"1.5 Storey\",\n",
    "    \"1 1/2 storey\": \"1.5 Storey\",\n",
    "    \"1 and half storey\": \"1.5 Storey\",\n",
    "    \"1.5 level\": \"1.5 Storey\",\n",
    "    \"1 3/4 storey\": \"1.5 Storey\",\n",
    "\n",
    "    # 2 Storey\n",
    "    \"2 storey\": \"2 Storey\",\n",
    "    \"two story\": \"2 Storey\",\n",
    "    \"2 level\": \"2 Storey\",\n",
    "    \"attached-si\": \"2 Storey\",    # Often attached 2 storey\n",
    "    \"2 storey split\": \"2 Storey\", # Or could be Split Level\n",
    "    \"two\": \"2 Storey\",\n",
    "    \"2\": \"2 Storey\",\n",
    "\n",
    "    # 2.5 Storey\n",
    "    \"2.5 storey\": \"2.5 Storey\",\n",
    "    \"2 1/2 storey\": \"2.5 Storey\",\n",
    "    \"2.5 level\": \"2.5 Storey\",\n",
    "\n",
    "    # 3 Storey and up\n",
    "    \"3 storey\": \"3 Storey\",\n",
    "    \"3-storey\": \"3 Storey\",\n",
    "    \"3 level\": \"3 Storey\",\n",
    "    \"3+ storey\": \"3+ Storey\",\n",
    "    \"3 plus stories\": \"3+ Storey\",\n",
    "    \"3 (or more) storey\": \"3+ Storey\",\n",
    "    \"3\": \"3 Storey\",\n",
    "    \"3.0\": \"3 Storey\",\n",
    "    \"three or more\": \"3+ Storey\",\n",
    "    \"3 level side split\": \"Split Level\",   # Likely split\n",
    "\n",
    "    # 4/5+ Storey (usually not single family, but handle for completeness)\n",
    "    \"4 level split\": \"Split Level\",\n",
    "    \"5 level split\": \"Split Level\",\n",
    "    \"5 level\": \"Split Level\",\n",
    "\n",
    "    # Split levels\n",
    "    \"split level\": \"Split Level\",\n",
    "    \"split entry\": \"Split Level\",\n",
    "    \"sidesplit\": \"Split Level\",\n",
    "    \"side split\": \"Split Level\",\n",
    "    \"sidesplit 3\": \"Split Level\",\n",
    "    \"sidesplit 4\": \"Split Level\",\n",
    "    \"backsplit\": \"Split Level\",\n",
    "    \"backsplit 3\": \"Split Level\",\n",
    "    \"backsplit 4\": \"Split Level\",\n",
    "    \"multi-level\": \"Split Level\",\n",
    "    \"multi level unit\": \"Split Level\",\n",
    "    \"multi level\": \"Split Level\",\n",
    "\n",
    "    # Bi-Level\n",
    "    \"bi-level\": \"Bi-Level\",\n",
    "    \"bi level\": \"Bi-Level\",\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `clean_story_group` Function\n",
    "\n",
    "This function standardizes story/style values for properties:\n",
    "\n",
    "- Cleans and lowercases the input.\n",
    "- Maps the value to a standard group using `STOREY_MAP` (with fuzzy matching).\n",
    "- If not found, checks for a standard group as a substring in the value.\n",
    "- Returns the standard group name, or `None` if no match is found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_story_group(value):\n",
    "    \"\"\"\n",
    "    Cleans up story/style values and groups into standard STORY_GROUPS for subject/comps.\n",
    "    \"\"\"\n",
    "    if not value or pd.isna(value):\n",
    "        return None\n",
    "    value = str(value).lower().strip()\n",
    "    mapped = get_manual_type_fuzzy(value, STOREY_MAP)\n",
    "    if mapped in STORY_GROUPS:\n",
    "        return mapped\n",
    "    # Substring fallback (catch e.g. \"something 2 Storey\", etc.)\n",
    "    for group in STORY_GROUPS:\n",
    "        if group.lower() in value:\n",
    "            return group\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original             â†’ Grouped As\n",
      "2 Storey             â†’ 2 Storey\n",
      "1.5 Storey           â†’ 1.5 Storey\n",
      "Bungalow             â†’ Bungalow\n",
      "1 Storey             â†’ 1 Storey\n",
      "4 Level Split        â†’ Split Level\n",
      "2-storey             â†’ 2 Storey\n",
      "Bungalow Raised      â†’ Bungalow Raised\n",
      "2.5 Storey           â†’ 2.5 Storey\n",
      "one level            â†’ 1 Storey\n",
      "3 Plus Stories       â†’ 3+ Storey\n",
      "Split Level          â†’ Split Level\n",
      "3+ Storey            â†’ 3+ Storey\n",
      "1 level              â†’ 1 Storey\n",
      "Bun                  â†’ Bungalow\n",
      "1                    â†’ 1 Storey\n"
     ]
    }
   ],
   "source": [
    "##-----------Test case---------##\n",
    "\n",
    "test_story_values = [\n",
    "    \"2 Storey\", \"1.5 Storey\", \"Bungalow\", \"1 Storey\", \"4 Level Split\",\n",
    "    \"2-storey\", \"Bungalow Raised\", \"2.5 Storey\", \"one level\",\n",
    "    \"3 Plus Stories\", \"Split Level\", \"3+ Storey\", \"1 level\", \"Bun\", '1'\n",
    "]\n",
    "\n",
    "print(\"Original\".ljust(20), \"â†’\", \"Grouped As\")\n",
    "for val in test_story_values:\n",
    "    print(val.ljust(20), \"â†’\", clean_story_group(val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Storey/Style for Candidate Properties\n",
    "\n",
    "This function cleans and standardizes the story/style type for candidate properties by:\n",
    "- Preferring the 'style' field, then checking 'levels' if needed.\n",
    "- Using our mapping and fallback logic to ensure values are grouped into standard STORY_GROUPS.\n",
    "- Returns None if no valid mapping is found.\n",
    "\n",
    "This helps make all storey/style data consistent for modeling and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_candidate_storey(row):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes story/style info for candidate properties.\n",
    "    Prefers 'style', then 'levels', else returns None.\n",
    "    Uses clean_story_group for the mapping logic.\n",
    "    \"\"\"\n",
    "    style = row.get('style', None)\n",
    "    levels = row.get('levels', None)\n",
    "\n",
    "    # Try style first\n",
    "    result = clean_story_group(style)\n",
    "    if result:\n",
    "        return result\n",
    "\n",
    "    # If style fails, try levels\n",
    "    result = clean_story_group(levels)\n",
    "    if result:\n",
    "        return result\n",
    "\n",
    "    # If both fail, return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- STANDARDIZATION TEST CASES ----\n",
      "Test  1: {'style': '2 Storey, Attached-Si', 'levels': '2 Storey, Attached-Si'} --> 2 Storey\n",
      "Test  2: {'style': 'Bungalow-Raised', 'levels': None} --> Bungalow Raised\n",
      "Test  3: {'style': None, 'levels': '1 1/2 Storey'} --> 1.5 Storey\n",
      "Test  4: {'style': '3-Storey', 'levels': '3 Level'} --> 3 Storey\n",
      "Test  5: {'style': 'Split Entry', 'levels': ''} --> Split Level\n",
      "Test  6: {'style': None, 'levels': None} --> None\n",
      "Test  7: {'style': 'Backsplit 4', 'levels': 'Split Level'} --> Split Level\n",
      "Test  8: {'style': 'Apartment-High-Rise', 'levels': None} --> None\n",
      "Test  9: {'style': '', 'levels': 'One Level'} --> 1 Storey\n",
      "Test 10: {'style': 'Something Unusual', 'levels': 'Something Else'} --> None\n",
      "Test 11: {'style': 'Bungaloft', 'levels': ''} --> Bungalow\n",
      "Test 12: {'style': '2', 'levels': ''} --> 2 Storey\n",
      "Test 13: {'style': 'Bi-Level', 'levels': None} --> Bi-Level\n"
     ]
    }
   ],
   "source": [
    "# --- Example Test Cases for standardize_candidate_storey ---\n",
    "\n",
    "test_rows = [\n",
    "    {'style': '2 Storey, Attached-Si', 'levels': '2 Storey, Attached-Si'},       # Should match '2 Storey'\n",
    "    {'style': 'Bungalow-Raised', 'levels': None},                                # Should match 'Bungalow Raised'\n",
    "    {'style': None, 'levels': '1 1/2 Storey'},                                   # Should match '1.5 Storey'\n",
    "    {'style': '3-Storey', 'levels': '3 Level'},                                  # Should match '3 Storey'\n",
    "    {'style': 'Split Entry', 'levels': ''},                                      # Should match 'Split Level'\n",
    "    {'style': None, 'levels': None},                                             # Should return None\n",
    "    {'style': 'Backsplit 4', 'levels': 'Split Level'},                           # Should match 'Split Level'\n",
    "    {'style': 'Apartment-High-Rise', 'levels': None},                            # Should return None (not in story group)\n",
    "    {'style': '', 'levels': 'One Level'},                                        # Should match '1 Storey'\n",
    "    {'style': 'Something Unusual', 'levels': 'Something Else'},                  # Should return None\n",
    "    {'style': 'Bungaloft', 'levels': ''},                                        # Should match 'Bungalow'\n",
    "    {'style': '2', 'levels': ''},                                                # Should match '2 Storey' (if mapped in STOREY_MAP)\n",
    "    {'style': 'Bi-Level', 'levels': None},                                       # Should match 'Bi-Level'\n",
    "]\n",
    "\n",
    "print(\"---- STANDARDIZATION TEST CASES ----\")\n",
    "for i, row in enumerate(test_rows, 1):\n",
    "    result = standardize_candidate_storey(row)\n",
    "    print(f\"Test {i:2}: {row} --> {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive data cleaning...\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Cleaning SUBJECTS data...\n",
      "  âœ“ Cleaned effective_date\n",
      "  âœ“ Cleaned lot_size_sf\n",
      "  âœ“ Cleaned gla\n",
      "  âœ“ Cleaned room_total\n",
      "  âœ“ Cleaned bed_count\n",
      "  âœ“ Cleaned num_baths\n",
      "  âœ“ Standardized property type\n",
      "  âœ“ Cleaned style\n",
      "\n",
      "ðŸ“‹ Cleaning COMPS data...\n",
      "  âœ“ Cleaned distance_to_subject\n",
      "  âœ“ Cleaned sale_date\n",
      "  âœ“ Cleaned lot_size\n",
      "  âœ“ Cleaned gla\n",
      "  âœ“ Cleaned room_count\n",
      "  âœ“ Cleaned bed_count\n",
      "  âœ“ Cleaned bath_count\n",
      "  âœ“ Standardized property type\n",
      "  âœ“ Cleaned stories\n",
      "\n",
      "ðŸ“‹ Cleaning CANDIDATES data...\n",
      "  âœ“ Cleaned close_date\n",
      "  âœ“ Cleaned lot_size_sf\n",
      "  âœ“ Cleaned gla\n",
      "  âœ“ Cleaned room_count\n",
      "  âœ“ Cleaned bedrooms\n",
      "  âœ“ Cleaned and combined full_baths and half_baths\n",
      "  âœ“ Standardized property type\n",
      "  âœ“ Standardized style/levels\n",
      "\n",
      "ðŸ“Š Cleaning Summary:\n",
      "--------------------------------------------------\n",
      "\n",
      "SUBJECTS (88 records):\n",
      "  - effective_date_clean: 88/88 (100.0% populated)\n",
      "  - lot_size_sf_clean: 72/88 (81.8% populated)\n",
      "  - gla_clean: 88/88 (100.0% populated)\n",
      "  - room_total_clean: 87/88 (98.9% populated)\n",
      "  - num_baths_clean: 87/88 (98.9% populated)\n",
      "  - property_type_clean: 87/88 (98.9% populated)\n",
      "  - style_clean: 88/88 (100.0% populated)\n",
      "\n",
      "COMPS (264 records):\n",
      "  - distance_to_subject_clean: 259/264 (98.1% populated)\n",
      "  - sale_date_clean: 264/264 (100.0% populated)\n",
      "  - lot_size_clean: 216/264 (81.8% populated)\n",
      "  - gla_clean: 264/264 (100.0% populated)\n",
      "  - room_count_clean: 264/264 (100.0% populated)\n",
      "  - bath_count_clean: 264/264 (100.0% populated)\n",
      "  - property_type_clean: 261/264 (98.9% populated)\n",
      "  - stories_clean: 262/264 (99.2% populated)\n",
      "\n",
      "CANDIDATES (9820 records):\n",
      "  - close_date_clean: 9820/9820 (100.0% populated)\n",
      "  - lot_size_sf_clean: 4944/9820 (50.3% populated)\n",
      "  - gla_clean: 9644/9820 (98.2% populated)\n",
      "  - room_count_clean: 9683/9820 (98.6% populated)\n",
      "  - total_baths_clean: 9820/9820 (100.0% populated)\n",
      "  - property_type_clean: 9800/9820 (99.8% populated)\n",
      "  - style_clean: 6455/9820 (65.7% populated)\n",
      "\n",
      "âœ… Data cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "def clean_all_property_data(subjects_df, comps_df, candidates_df):\n",
    "    \"\"\"\n",
    "    Master function to clean all property datasets with all the cleaning functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - subjects_df: DataFrame with subject properties\n",
    "    - comps_df: DataFrame with comp properties  \n",
    "    - candidates_df: DataFrame with candidate properties\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple of (cleaned_subjects_df, cleaned_comps_df, cleaned_candidates_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make copies to avoid modifying originals\n",
    "    subjects_clean = subjects_df.copy()\n",
    "    comps_clean = comps_df.copy()\n",
    "    candidates_clean = candidates_df.copy()\n",
    "    \n",
    "    print(\"Starting comprehensive data cleaning...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # ========== CLEAN SUBJECTS ==========\n",
    "    print(\"\\nðŸ“‹ Cleaning SUBJECTS data...\")\n",
    "    \n",
    "    # Clean dates\n",
    "    if 'effective_date' in subjects_clean.columns:\n",
    "        subjects_clean['effective_date_clean'] = subjects_clean['effective_date'].apply(clean_date)\n",
    "        print(f\"  âœ“ Cleaned effective_date\")\n",
    "    \n",
    "    # Clean lot size\n",
    "    if 'lot_size_sf' in subjects_clean.columns:\n",
    "        subjects_clean['lot_size_sf_clean'] = subjects_clean['lot_size_sf'].apply(clean_numeric_with_units)\n",
    "        print(f\"  âœ“ Cleaned lot_size_sf\")\n",
    "    \n",
    "    # Clean GLA (Gross Living Area)\n",
    "    if 'gla' in subjects_clean.columns:\n",
    "        subjects_clean['gla_clean'] = subjects_clean['gla'].apply(clean_numeric_with_units)\n",
    "        print(f\"  âœ“ Cleaned gla\")\n",
    "    \n",
    "    # Clean room counts\n",
    "    if 'room_total' in subjects_clean.columns:\n",
    "        subjects_clean['room_total_clean'] = subjects_clean['room_total'].apply(clean_room_count)\n",
    "        print(f\"  âœ“ Cleaned room_total\")\n",
    "    \n",
    "    # Clean bedrooms\n",
    "    if 'num_beds' in subjects_clean.columns:\n",
    "        subjects_clean['num_beds_clean'] = subjects_clean['num_beds'].apply(clean_room_count)\n",
    "        print(f\"  âœ“ Cleaned bed_count\")\n",
    "    \n",
    "    # Clean bathrooms\n",
    "    if 'num_baths' in subjects_clean.columns:\n",
    "        subjects_clean['num_baths_clean'] = subjects_clean['num_baths'].apply(clean_bathroom_count)\n",
    "        print(f\"  âœ“ Cleaned num_baths\")\n",
    "    \n",
    "    # Standardize property type (using structure_type for subjects)\n",
    "    if 'structure_type' in subjects_clean.columns:\n",
    "        subjects_clean['property_type_clean'] = subjects_clean.apply(\n",
    "            lambda row: standardize_property_type({'property_sub_type': None, 'structure_type': row['structure_type']}), \n",
    "            axis=1\n",
    "        )\n",
    "        print(f\"  âœ“ Standardized property type\")\n",
    "    \n",
    "    # Clean story/style\n",
    "    if 'style' in subjects_clean.columns:\n",
    "        subjects_clean['style_clean'] = subjects_clean['style'].apply(clean_story_group)\n",
    "        print(f\"  âœ“ Cleaned style\")\n",
    "    \n",
    "    # ========== CLEAN COMPS ==========\n",
    "    print(\"\\nðŸ“‹ Cleaning COMPS data...\")\n",
    "    \n",
    "    # Clean distance\n",
    "    if 'distance_to_subject' in comps_clean.columns:\n",
    "        comps_clean['distance_to_subject_clean'] = comps_clean['distance_to_subject'].apply(clean_distance)\n",
    "        print(f\"  âœ“ Cleaned distance_to_subject\")\n",
    "    \n",
    "    # Clean dates\n",
    "    if 'sale_date' in comps_clean.columns:\n",
    "        comps_clean['sale_date_clean'] = comps_clean['sale_date'].apply(clean_date)\n",
    "        print(f\"  âœ“ Cleaned sale_date\")\n",
    "    \n",
    "    # Clean lot size\n",
    "    if 'lot_size' in comps_clean.columns:\n",
    "        comps_clean['lot_size_clean'] = comps_clean['lot_size'].apply(clean_numeric_with_units)\n",
    "        print(f\"  âœ“ Cleaned lot_size\")\n",
    "    \n",
    "    # Clean GLA\n",
    "    if 'gla' in comps_clean.columns:\n",
    "        comps_clean['gla_clean'] = comps_clean['gla'].apply(clean_numeric_with_units)\n",
    "        print(f\"  âœ“ Cleaned gla\")\n",
    "    \n",
    "    # Clean room count\n",
    "    if 'room_count' in comps_clean.columns:\n",
    "        comps_clean['room_count_clean'] = comps_clean['room_count'].apply(clean_room_count)\n",
    "        print(f\"  âœ“ Cleaned room_count\")\n",
    "    \n",
    "    # Clean bedrooms\n",
    "    if 'bed_count' in comps_clean.columns:\n",
    "        comps_clean['bed_count_clean'] = comps_clean['bed_count'].apply(clean_room_count)\n",
    "        print(f\"  âœ“ Cleaned bed_count\")\n",
    "        \n",
    "    # Clean bathrooms\n",
    "    if 'bath_count' in comps_clean.columns:\n",
    "        comps_clean['bath_count_clean'] = comps_clean['bath_count'].apply(clean_bathroom_count)\n",
    "        print(f\"  âœ“ Cleaned bath_count\")\n",
    "    \n",
    "    # Standardize property type\n",
    "    if 'prop_type' in comps_clean.columns:\n",
    "        comps_clean['property_type_clean'] = comps_clean.apply(\n",
    "            lambda row: standardize_property_type({'property_sub_type': row.get('prop_type'), 'structure_type': None}), \n",
    "            axis=1\n",
    "        )\n",
    "        print(f\"  âœ“ Standardized property type\")\n",
    "    \n",
    "    # Clean stories\n",
    "    if 'stories' in comps_clean.columns:\n",
    "        comps_clean['stories_clean'] = comps_clean['stories'].apply(clean_story_group)\n",
    "        print(f\"  âœ“ Cleaned stories\")\n",
    "    \n",
    "    # ========== CLEAN CANDIDATES ==========\n",
    "    print(\"\\nðŸ“‹ Cleaning CANDIDATES data...\")\n",
    "    \n",
    "    # Clean dates\n",
    "    if 'close_date' in candidates_clean.columns:\n",
    "        candidates_clean['close_date_clean'] = candidates_clean['close_date'].apply(clean_date)\n",
    "        print(f\"  âœ“ Cleaned close_date\")\n",
    "    \n",
    "    # Clean lot size\n",
    "    if 'lot_size_sf' in candidates_clean.columns:\n",
    "        candidates_clean['lot_size_sf_clean'] = candidates_clean['lot_size_sf'].apply(clean_numeric_with_units)\n",
    "        print(f\"  âœ“ Cleaned lot_size_sf\")\n",
    "    \n",
    "    # Clean GLA\n",
    "    if 'gla' in candidates_clean.columns:\n",
    "        candidates_clean['gla_clean'] = candidates_clean['gla'].apply(clean_numeric_with_units)\n",
    "        print(f\"  âœ“ Cleaned gla\")\n",
    "    \n",
    "    # Clean room count\n",
    "    if 'room_count' in candidates_clean.columns:\n",
    "        candidates_clean['room_count_clean'] = candidates_clean['room_count'].apply(clean_room_count)\n",
    "        print(f\"  âœ“ Cleaned room_count\")\n",
    "    \n",
    "\n",
    "    # Clean bedroom \n",
    "    if 'bedrooms' in candidates_clean.columns:\n",
    "        candidates_clean['bedrooms_clean'] = candidates_clean['bedrooms'].apply(clean_room_count)\n",
    "        print(f\"  âœ“ Cleaned bedrooms\")\n",
    "\n",
    "    # Clean bathrooms (handle full and half separately, then combine)\n",
    "    if 'full_baths' in candidates_clean.columns and 'half_baths' in candidates_clean.columns:\n",
    "        candidates_clean['full_baths_clean'] = pd.to_numeric(candidates_clean['full_baths'], errors='coerce')\n",
    "        candidates_clean['half_baths_clean'] = pd.to_numeric(candidates_clean['half_baths'], errors='coerce')\n",
    "        candidates_clean['total_baths_clean'] = (\n",
    "            candidates_clean['full_baths_clean'].fillna(0) + \n",
    "            (candidates_clean['half_baths_clean'].fillna(0) * 0.5)\n",
    "        )\n",
    "        print(f\"  âœ“ Cleaned and combined full_baths and half_baths\")\n",
    "    \n",
    "    # Standardize property type\n",
    "    if 'property_sub_type' in candidates_clean.columns or 'structure_type' in candidates_clean.columns:\n",
    "        candidates_clean['property_type_clean'] = candidates_clean.apply(standardize_property_type, axis=1)\n",
    "        print(f\"  âœ“ Standardized property type\")\n",
    "    \n",
    "    # Standardize story/style\n",
    "    if 'style' in candidates_clean.columns or 'levels' in candidates_clean.columns:\n",
    "        candidates_clean['style_clean'] = candidates_clean.apply(standardize_candidate_storey, axis=1)\n",
    "        print(f\"  âœ“ Standardized style/levels\")\n",
    "    \n",
    "    # ========== SUMMARY STATISTICS ==========\n",
    "    print(\"\\nðŸ“Š Cleaning Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Subjects summary\n",
    "    print(f\"\\nSUBJECTS ({len(subjects_clean)} records):\")\n",
    "    for col in ['effective_date_clean', 'lot_size_sf_clean', 'gla_clean', 'room_total_clean', \n",
    "                'num_baths_clean', 'property_type_clean', 'style_clean']:\n",
    "        if col in subjects_clean.columns:\n",
    "            non_null = subjects_clean[col].notna().sum()\n",
    "            pct = (non_null / len(subjects_clean)) * 100\n",
    "            print(f\"  - {col}: {non_null}/{len(subjects_clean)} ({pct:.1f}% populated)\")\n",
    "    \n",
    "    # Comps summary\n",
    "    print(f\"\\nCOMPS ({len(comps_clean)} records):\")\n",
    "    for col in ['distance_to_subject_clean', 'sale_date_clean', 'lot_size_clean', 'gla_clean',\n",
    "                'room_count_clean', 'bath_count_clean', 'property_type_clean', 'stories_clean']:\n",
    "        if col in comps_clean.columns:\n",
    "            non_null = comps_clean[col].notna().sum()\n",
    "            pct = (non_null / len(comps_clean)) * 100\n",
    "            print(f\"  - {col}: {non_null}/{len(comps_clean)} ({pct:.1f}% populated)\")\n",
    "    \n",
    "    # Candidates summary\n",
    "    print(f\"\\nCANDIDATES ({len(candidates_clean)} records):\")\n",
    "    for col in ['close_date_clean', 'lot_size_sf_clean', 'gla_clean', 'room_count_clean',\n",
    "                'total_baths_clean', 'property_type_clean', 'style_clean']:\n",
    "        if col in candidates_clean.columns:\n",
    "            non_null = candidates_clean[col].notna().sum()\n",
    "            pct = (non_null / len(candidates_clean)) * 100\n",
    "            print(f\"  - {col}: {non_null}/{len(candidates_clean)} ({pct:.1f}% populated)\")\n",
    "    \n",
    "    print(\"\\nâœ… Data cleaning complete!\")\n",
    "    \n",
    "    return subjects_clean, comps_clean, candidates_clean\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "cleaned_subjects, cleaned_comps, cleaned_candidates = clean_all_property_data(    \n",
    "    subjects_df, comps_df, candidates_df\n",
    ")\n",
    "\n",
    "# Optional: Save cleaned data\n",
    "cleaned_subjects.to_csv('datasets/data/subjects_cleaned.csv', index=False)\n",
    "cleaned_comps.to_csv('datasets/data/comps_cleaned.csv', index=False)  \n",
    "cleaned_candidates.to_csv('datasets/data/candidates_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_property_data(subjects_df, comps_df, candidates_df):\n",
    "    \"\"\"\n",
    "    Master function to clean all property datasets with consistent clean column names.\n",
    "    \"\"\"\n",
    "    # Make copies\n",
    "    subjects_clean = subjects_df.copy()\n",
    "    comps_clean = comps_df.copy()\n",
    "    candidates_clean = candidates_df.copy()\n",
    "    \n",
    "    print(\"Starting comprehensive data cleaning...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # ========== CLEAN SUBJECTS ==========\n",
    "    print(\"\\nðŸ“‹ Cleaning SUBJECTS data...\")\n",
    "    subjects_clean['effective_date_clean'] = subjects_clean['effective_date'].apply(clean_date)\n",
    "    subjects_clean['lot_size_clean'] = subjects_clean['lot_size_sf'].apply(clean_numeric_with_units)\n",
    "    subjects_clean['gla_clean'] = subjects_clean['gla'].apply(clean_numeric_with_units)\n",
    "    subjects_clean['bedrooms_clean'] = subjects_clean['num_beds'].apply(clean_room_count)\n",
    "    subjects_clean['bathrooms_clean'] = subjects_clean['num_baths'].apply(clean_bathroom_count)\n",
    "    subjects_clean['property_type_clean'] = subjects_clean.apply(\n",
    "        lambda row: standardize_property_type({'property_sub_type': None, 'structure_type': row['structure_type']}), axis=1)\n",
    "    subjects_clean['stories_clean'] = subjects_clean['style'].apply(clean_story_group)\n",
    "    subjects_clean['style_clean'] = subjects_clean['style'].apply(clean_story_group)  # Optionally keep for style\n",
    "\n",
    "    # ========== CLEAN COMPS ==========\n",
    "    print(\"\\nðŸ“‹ Cleaning COMPS data...\")\n",
    "    comps_clean['distance_to_subject_clean'] = comps_clean['distance_to_subject'].apply(clean_distance)\n",
    "    comps_clean['sale_date_clean'] = comps_clean['sale_date'].apply(clean_date)\n",
    "    comps_clean['lot_size_clean'] = comps_clean['lot_size'].apply(clean_numeric_with_units)\n",
    "    comps_clean['gla_clean'] = comps_clean['gla'].apply(clean_numeric_with_units)\n",
    "    comps_clean['bedrooms_clean'] = comps_clean['bed_count'].apply(clean_room_count)\n",
    "    comps_clean['bathrooms_clean'] = comps_clean['bath_count'].apply(clean_bathroom_count)\n",
    "    comps_clean['property_type_clean'] = comps_clean.apply(\n",
    "        lambda row: standardize_property_type({'property_sub_type': row.get('prop_type'), 'structure_type': None}), axis=1)\n",
    "    comps_clean['stories_clean'] = comps_clean['stories'].apply(clean_story_group)\n",
    "    comps_clean['style_clean'] = comps_clean['stories'].apply(clean_story_group)  # Optionally keep for style\n",
    "\n",
    "    # ========== CLEAN CANDIDATES ==========\n",
    "    print(\"\\nðŸ“‹ Cleaning CANDIDATES data...\")\n",
    "    candidates_clean['close_date_clean'] = candidates_clean['close_date'].apply(clean_date)\n",
    "    candidates_clean['lot_size_clean'] = candidates_clean['lot_size_sf'].apply(clean_numeric_with_units)\n",
    "    candidates_clean['gla_clean'] = candidates_clean['gla'].apply(clean_numeric_with_units)\n",
    "    candidates_clean['bedrooms_clean'] = candidates_clean['bedrooms'].apply(clean_room_count)\n",
    "    # Bathrooms: combine full & half into a single clean value\n",
    "    candidates_clean['full_baths_clean'] = pd.to_numeric(candidates_clean['full_baths'], errors='coerce')\n",
    "    candidates_clean['half_baths_clean'] = pd.to_numeric(candidates_clean['half_baths'], errors='coerce')\n",
    "    candidates_clean['bathrooms_clean'] = (\n",
    "        candidates_clean['full_baths_clean'].fillna(0) +\n",
    "        (candidates_clean['half_baths_clean'].fillna(0) * 0.5)\n",
    "    )\n",
    "    candidates_clean['property_type_clean'] = candidates_clean.apply(standardize_property_type, axis=1)\n",
    "    candidates_clean['stories_clean'] = candidates_clean.apply(standardize_candidate_storey, axis=1)\n",
    "    candidates_clean['style_clean'] = candidates_clean['style'].apply(standardize_candidate_storey)  # Optionally keep for style\n",
    "\n",
    "    # ========== SUMMARY STATISTICS ==========\n",
    "    print(\"\\nðŸ“Š Cleaning Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"\\nSUBJECTS ({len(subjects_clean)} records):\")\n",
    "    for col in ['effective_date_clean', 'lot_size_clean', 'gla_clean', 'bedrooms_clean', 'bathrooms_clean', 'property_type_clean', 'stories_clean']:\n",
    "        non_null = subjects_clean[col].notna().sum()\n",
    "        pct = (non_null / len(subjects_clean)) * 100\n",
    "        print(f\"  - {col}: {non_null}/{len(subjects_clean)} ({pct:.1f}% populated)\")\n",
    "    \n",
    "    print(f\"\\nCOMPS ({len(comps_clean)} records):\")\n",
    "    for col in ['distance_to_subject_clean', 'sale_date_clean', 'lot_size_clean', 'gla_clean', 'bedrooms_clean', 'bathrooms_clean', 'property_type_clean', 'stories_clean']:\n",
    "        non_null = comps_clean[col].notna().sum()\n",
    "        pct = (non_null / len(comps_clean)) * 100\n",
    "        print(f\"  - {col}: {non_null}/{len(comps_clean)} ({pct:.1f}% populated)\")\n",
    "    \n",
    "    print(f\"\\nCANDIDATES ({len(candidates_clean)} records):\")\n",
    "    for col in ['close_date_clean', 'lot_size_clean', 'gla_clean', 'bedrooms_clean', 'bathrooms_clean', 'property_type_clean', 'stories_clean']:\n",
    "        non_null = candidates_clean[col].notna().sum()\n",
    "        pct = (non_null / len(candidates_clean)) * 100\n",
    "        print(f\"  - {col}: {non_null}/{len(candidates_clean)} ({pct:.1f}% populated)\")\n",
    "    \n",
    "    print(\"\\nâœ… Data cleaning complete!\")\n",
    "    return subjects_clean, comps_clean, candidates_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subjects, cleaned_comps, cleaned_candidates = clean_all_property_data(\n",
    "    subjects_df, comps_df, candidates_df\n",
    ")\n",
    "# Save as needed:\n",
    "cleaned_subjects.to_csv('datasets/data/subjects_cleaned.csv', index=False)\n",
    "cleaned_comps.to_csv('datasets/data/comps_cleaned.csv', index=False)  \n",
    "cleaned_candidates.to_csv('datasets/data/candidates_cleaned.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
